{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Change `repo_path` to try different examples"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from aibro.inference import Inference\n",
    "\n",
    "repo_path = 'pytorch_hub_DieT'\n",
    "# repo_path = 'sklearn_random_forest'\n",
    "# repo_path = 'sentiment_model_repo'\n",
    "Inference.deploy(\n",
    "    repo_path,\n",
    "    dryrun=True,\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: numpy==1.21.5 in ./repo_venv/lib/python3.8/site-packages (from -r /home/lilounan/src/AIbro_model_repo/pytorch_hub_DieT/requirements.txt (line 9)) (1.21.5)\n",
      "Requirement already satisfied: pillow==9.0.1 in ./repo_venv/lib/python3.8/site-packages (from -r /home/lilounan/src/AIbro_model_repo/pytorch_hub_DieT/requirements.txt (line 11)) (9.0.1)\n",
      "Requirement already satisfied: timm==0.5.4 in ./repo_venv/lib/python3.8/site-packages (from -r /home/lilounan/src/AIbro_model_repo/pytorch_hub_DieT/requirements.txt (line 13)) (0.5.4)\n",
      "Requirement already satisfied: torch==1.10.2 in ./repo_venv/lib/python3.8/site-packages (from -r /home/lilounan/src/AIbro_model_repo/pytorch_hub_DieT/requirements.txt (line 15)) (1.10.2)\n",
      "Requirement already satisfied: torchvision==0.11.3 in ./repo_venv/lib/python3.8/site-packages (from -r /home/lilounan/src/AIbro_model_repo/pytorch_hub_DieT/requirements.txt (line 19)) (0.11.3)\n",
      "Requirement already satisfied: typing-extensions==4.0.1 in ./repo_venv/lib/python3.8/site-packages (from -r /home/lilounan/src/AIbro_model_repo/pytorch_hub_DieT/requirements.txt (line 21)) (4.0.1)\n",
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/lilounan/src/AIbro_model_repo/repo_venv/bin/python3 -m pip install --upgrade pip' command.\n",
      "Dependencies installed!\n",
      "1.10.2+cu102\n",
      "Using cache found in /home/lilounan/.cache/torch/hub/facebookresearch_deit_main\n",
      "/home/lilounan/src/AIbro_model_repo/repo_venv/lib/python3.8/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "Prediction finished without error\n",
      "\u001b[32mDRYRUN TEST: passed\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from aibro.inference import Inference\n",
    "\n",
    "api_url = Inference.deploy(\n",
    "    model_name = \"DieT\",\n",
    "    machine_id_config = \"c5.large.od\",\n",
    "    artifacts_path = repo_path,\n",
    "    client_ids = [] # if no clients are specified, the inference job becomes public\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Please open https://aipaca.ai/inference_jobs to track job status.\n",
      "[LAUNCHING]: Starting public inference job: inf_a388beea-b8f2-49d1-ab15-526cfad121fc\n",
      "[LAUNCHING]: Requesting {'standby': 'c5.large.od'} to be ready...\n",
      "[LAUNCHING]: Started a standby c5.large.od.\n",
      "[LAUNCHING]: c5.large.od server successfully requested, launching and building...\n",
      "[LAUNCHING]: [ Getting server ready in around: 1 minute ]\n",
      "Your {'standby': 'c5.large.od'} instances are now ready ðŸŽ‰\n",
      "\n",
      "[SENDING]: Serializing your artifacts...\n",
      "\u001b[?25l"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[SENDING]: |>>>>>>>>> | 90.03 % 0.13 / 0.15 MiB [avg: 0.51MiB/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[?25h"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[SENDING]: |>>>>>>>>>>| 100.00 % 0.15 / 0.15 MiB [avg: 0.28MiB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[32mYour Inference API URL: http://api.aipaca.ai/v1/sggbond97/public/DieT/predict\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference paradigm using curl:\n",
    "1. to inference a zip file\n",
    "!curl -X POST {{your_inference_api_url}} -d 'path/to/repo/data.zip'\n",
    "2. to inference a json data\n",
    "!curl -X POST {{your_inference_api_url}} -d '{'key': value, ...}'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "!curl -X POST {{http://api.aipaca.ai/v1/sggbond97/public/DieT/predict}} -d 'pytorch_hub_DieT/data.zip'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "269"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Limit API Access to Specific Clients (Optional)\n",
    "\n",
    "As the API owner, you probably don't receive overwhelming API requests from everywhere. To avoid this trouble, you could give every client an unique client id, which is going to used in API endpoint (as the shown syntax in the step 4). If no client id was added, this inference job would be public by default."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from aibro.inference import Inference\n",
    "Inference.update_clients(\n",
    "    job_id = \"inf_f8eef73f-048a-4c08-b5de-cadc769a7f11\",\n",
    "    add_client_ids = [\"client_1\", \"client_2\"]\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!curl -d 'pytorch_hub_DieT/data.zip' -X POST {{http://api.aipaca.ai/v1/sggbond97/public/DieT/predict}}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complete Job\n",
    "\n",
    "Once the inference job is no longer used, to avoid unnecessary cost, please remember to close it by Inference.complete()."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "Inference.complete(job_id=\"inf_a388beea-b8f2-49d1-ab15-526cfad121fc\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Inference job inf_a388beea-b8f2-49d1-ab15-526cfad121fc, with model DieT, successfully completed.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20005f515ab61bc93f552b80c574da19aced5c52fcaf5bd6161f151586e2ff14"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('repo_venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}